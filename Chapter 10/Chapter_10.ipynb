{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## DP Credit Card Detection"
      ],
      "metadata": {
        "id": "VI4JEB9Fx60l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Library Imports"
      ],
      "metadata": {
        "id": "9IGd1mIuysqP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rKBlpdkuPBn"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from diffprivlib.models import LogisticRegression as dpLogisticRegression\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Setup"
      ],
      "metadata": {
        "id": "r3Oip0JJyvBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/nsethi31/Kaggle-Data-Credit-Card-Fraud-Detection/master/creditcard.csv\"\n",
        "df = pd.read_csv(url)\n"
      ],
      "metadata": {
        "id": "5mC4pwAZu3GR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "id": "zP-PTuS8u8Pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df['Class'].values\n",
        "X = df.drop('Time', axis = 1).drop('Class', axis = 1).values\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, \n",
        "                                       Y, \n",
        "                                       test_size=0.2, \n",
        "                                       random_state=123)\n"
      ],
      "metadata": {
        "id": "u56WQsFIu-1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DP Logistic Regression"
      ],
      "metadata": {
        "id": "SaEAbIa5yyFO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Base Model (no DP)"
      ],
      "metadata": {
        "id": "mHQ0PULky0rA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a regular logistic regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "bt2CbJDCvBt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "score = model.score(X_test, y_test)\n",
        "print(\"Test set accuracy for regular logistic regression: {:.2f}%\".format(score*100))\n"
      ],
      "metadata": {
        "id": "nV1_VH4fvD3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model with DP"
      ],
      "metadata": {
        "id": "0cPDt4V6y4Lw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a differentially private logistic regression model\n",
        "dp_model = dpLogisticRegression(epsilon=1.0, data_norm=10)\n",
        "dp_model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "jOCYv1yXvG5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "score = dp_model.score(X_test, y_test)\n",
        "print(\"Test set accuracy for differentially private logistic regression: {:.2f}%\".format(score*100))\n"
      ],
      "metadata": {
        "id": "7OBdZ-vDvJIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DP Random Forest"
      ],
      "metadata": {
        "id": "_KIIEbdNy7HD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from diffprivlib.models import RandomForestClassifier as dpRandomForestClassifier\n",
        "\n",
        "# Train a regular logistic regression model\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "score = model.score(X_test, y_test)\n",
        "print(\"Test set accuracy for regular RF: {:.2f}%\".format(score*100))\n",
        "\n",
        "# Train a differentially private logistic regression model\n",
        "dp_model = dpRandomForestClassifier(epsilon=1.0, data_norm=10)\n",
        "dp_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "score = dp_model.score(X_test, y_test)\n",
        "print(\"Test set accuracy for differentially private RF: {:.2f}%\".format(score*100))\n"
      ],
      "metadata": {
        "id": "Xng0PAz2xOM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Examining the effect of Ïµ"
      ],
      "metadata": {
        "id": "MmtG5naxza0a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Logistic Regression"
      ],
      "metadata": {
        "id": "vVumLPwFzggZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "EPS_MIN = 0.1\n",
        "EPS_MAX = 10\n",
        "STEP_SIZE = 0.1\n",
        "scores = []\n",
        "\n",
        "epsilons = np.arange(EPS_MIN, EPS_MAX, STEP_SIZE)\n",
        "\n",
        "for eps in epsilons:\n",
        "\n",
        "  # Train a differentially private logistic regression model\n",
        "  dp_model = dpLogisticRegression(epsilon= eps, \n",
        "                                  data_norm=10)\n",
        "  dp_model.fit(X_train, y_train)\n",
        "\n",
        "  # Evaluate the model on the test set\n",
        "  score = dp_model.score(X_test, y_test)\n",
        "  scores.append(100.0*score)\n"
      ],
      "metadata": {
        "id": "HS-QuqW-xR13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "plt.plot(epsilons, scores)\n"
      ],
      "metadata": {
        "id": "zGsMQzY6xUfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Random Forest"
      ],
      "metadata": {
        "id": "mpnYLp68zkEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "EPS_MIN = 0.1\n",
        "EPS_MAX = 10\n",
        "STEP_SIZE = 0.1\n",
        "scores = []\n",
        "\n",
        "epsilons = np.arange(EPS_MIN, EPS_MAX, STEP_SIZE)\n",
        "\n",
        "for eps in epsilons:\n",
        "\n",
        "  # Train a differentially private logistic regression model\n",
        "  dp_model = dpRandomForestClassifier(epsilon= eps, \n",
        "                                  data_norm=10)\n",
        "  dp_model.fit(X_train, y_train)\n",
        "\n",
        "  # Evaluate the model on the test set\n",
        "  score = dp_model.score(X_test, y_test)\n",
        "  scores.append(100.0*score)\n"
      ],
      "metadata": {
        "id": "3NAsMj0-xZpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Differentially Private Deep Learning"
      ],
      "metadata": {
        "id": "p_I6kaExznuv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Library Imports"
      ],
      "metadata": {
        "id": "Il0JrNj9zxRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow_privacy\n",
        "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n"
      ],
      "metadata": {
        "id": "vEu_wOHlxbL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Setup"
      ],
      "metadata": {
        "id": "773BywTsz0xu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_process_MNIST_Data():\n",
        "\n",
        "    # Define constants\n",
        "    SCALE_FACTOR = 1/255\n",
        "    NUM_CLASS = 10\n",
        "\n",
        "    # Load train and test data\n",
        "    train, test = tf.keras.datasets.mnist.load_data()\n",
        "    train_data, train_labels = train\n",
        "    test_data, test_labels = test\n",
        "    print(\"----- Loaded Train and Test Raw Data -----\")\n",
        "\n",
        "    # Scale train and test data\n",
        "    train_data = np.array(train_data, dtype=np.float32) * SCALE_FACTOR\n",
        "    test_data = np.array(test_data, dtype=np.float32) * SCALE_FACTOR\n",
        "    print(\"----- Scaled Train and Test Data -----\")\n",
        "\n",
        "    # Reshape data for Convolutional NN\n",
        "    train_data = train_data.reshape(train_data.shape[0], 28, 28, 1)\n",
        "    test_data = test_data.reshape(test_data.shape[0], 28, 28, 1)\n",
        "    print(\"----- Reshaped Train and Test Data -----\")\n",
        "\n",
        "    # Load train and test labels\n",
        "    train_labels = np.array(train_labels, dtype=np.int32)\n",
        "    test_labels = np.array(test_labels, dtype=np.int32)\n",
        "    print(\"----- Loaded Train and Test Labels -----\")\n",
        "\n",
        "    # One-Hot Encode the labels\n",
        "    train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=NUM_CLASS)\n",
        "    test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=NUM_CLASS)\n",
        "    print(\"----- Categorized Train and Test Labels -----\")\n",
        "\n",
        "    return train_data, train_labels, test_data, test_labels\n"
      ],
      "metadata": {
        "id": "bSqw-7ygxeAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN Classification Model"
      ],
      "metadata": {
        "id": "TYS6nUeF_Udl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MNIST_CNN_Model (num_hidden = 1):\n",
        "    model_layers = list()\n",
        "\n",
        "    # Add input layer\n",
        "\n",
        "    # Convolution\n",
        "    model_layers.append(tf.keras.layers.Conv2D(16, 8,\n",
        "                           strides=2,\n",
        "                           padding='same',\n",
        "                           activation='relu',\n",
        "                           input_shape=(28, 28, 1)))\n",
        "    \n",
        "    # Pooling\n",
        "    model_layers.append(tf.keras.layers.MaxPool2D(2, 1))\n",
        "\n",
        "    # Add Hidden Layers\n",
        "    for _ in range(num_hidden):\n",
        "\n",
        "        # Convolution\n",
        "        model_layers.append(tf.keras.layers.Conv2D(32, 4,\n",
        "                           strides=2,\n",
        "                           padding='valid',\n",
        "                           activation='relu'))\n",
        "        \n",
        "        # Pooling\n",
        "        model_layers.append(tf.keras.layers.MaxPool2D(2, 1))\n",
        "\n",
        "    # Flatten to vector\n",
        "    model_layers.append(tf.keras.layers.Flatten())\n",
        "\n",
        "    # Final Dense Layer\n",
        "    model_layers.append(tf.keras.layers.Dense(32, activation='relu'))\n",
        "    model_layers.append(tf.keras.layers.Dense(10))\n",
        "\n",
        "    # Initialize model with these layers\n",
        "    model = tf.keras.Sequential(model_layers)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "nnAAfLOyxhLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training"
      ],
      "metadata": {
        "id": "o_D-c5vx_ZPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, train_labels, test_data, test_labels = load_and_process_MNIST_Data()"
      ],
      "metadata": {
        "id": "8jVO-IQkxlBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 3\n",
        "BATCH_SIZE = 250\n",
        "MICRO_BATCHES = 250\n",
        "L2_NORM_CLIP = 1.5\n",
        "NOISE_MULTIPLIER = 1.3\n",
        "LEARN_RATE = 0.2\n",
        "\n",
        "model = MNIST_CNN_Model()\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "tatHk05Lxn3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tensorflow_privacy.DPKerasSGDOptimizer(\n",
        "                  l2_norm_clip = L2_NORM_CLIP,\n",
        "                  noise_multiplier = NOISE_MULTIPLIER,\n",
        "                  num_microbatches = MICRO_BATCHES,\n",
        "                  learning_rate = LEARN_RATE)\n",
        "\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(\n",
        "                  from_logits=True, \n",
        "                  reduction=tf.losses.Reduction.NONE)\n"
      ],
      "metadata": {
        "id": "5rULHT_2xsOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=optimizer, \n",
        "              loss=loss, \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_data, \n",
        "          train_labels,\n",
        "          epochs = NUM_EPOCHS,\n",
        "          validation_data = (test_data, test_labels),\n",
        "          batch_size = BATCH_SIZE)\n"
      ],
      "metadata": {
        "id": "GTmhbWd5xwAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_dp_sgd_privacy.compute_dp_sgd_privacy(\n",
        "                  n = train_data.shape[0],\n",
        "                  batch_size = BATCH_SIZE,\n",
        "                  noise_multiplier = NOISE_MULTIPLIER,\n",
        "                  epochs = NUM_EPOCHS,\n",
        "                  delta=1e-5)\n"
      ],
      "metadata": {
        "id": "nlrbpqaGx1Rf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}