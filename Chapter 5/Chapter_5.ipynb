{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Deepfake Images"
      ],
      "metadata": {
        "id": "f-QfJwnfN9Z8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Libraries"
      ],
      "metadata": {
        "id": "JG89AvsvOCgX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AE6M5mmoHRH5"
      },
      "outputs": [],
      "source": [
        "# Data Processing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.misc\n",
        "from sklearn.datasets import load_files \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Deep Learning Libraries\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, Activation, Lambda, Permute, Reshape\n",
        "from keras.layers import Convolution2D, ZeroPadding2D, MaxPooling2D\n",
        "from keras_vggface.vggface import VGGFace\n",
        "from keras_vggface import utils\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loading"
      ],
      "metadata": {
        "id": "Uku5KQcuOH8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data_path = \"\"\n",
        "test_data_path = \"\"\n",
        "batch_size = 64\n",
        "\n",
        "print(“Loading Train…”)\n",
        "training_data = ImageDataGenerator(rescale = 1./255.) \n",
        "                .flow_from_directory(\n",
        "                        training_data_path,\n",
        "                        target_size=(224, 224),\n",
        "                        batch_size=batch_size,\n",
        "                        class_mode='binary'\n",
        "                )\n",
        "\n",
        "\n",
        "print(“Loading Test…”)\n",
        "test_data = ImageDataGenerator(rescale = 1./255.)\n",
        "            .flow_from_directory(\n",
        "                        test_data_path,\n",
        "                        target_size=(224, 224),\n",
        "                        batch_size=batch_size,\n",
        "                        class_mode='binary'\n",
        "            )"
      ],
      "metadata": {
        "id": "Cp1TU29_I6-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN Model"
      ],
      "metadata": {
        "id": "giRq77hROMeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (224,224,3)\n",
        "epsilon=0.001\n",
        "dropout = 0.1\n",
        "model = Sequential()\n",
        "\n",
        "# Convolution and Pooling\n",
        "model.add(BatchNormalization(input_shape=input_shape))\n",
        "model.add(Conv2D(filters=16, kernel_size=3, activation='relu', padding=’same’))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(BatchNormalization(epsilon=epsilon))\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=3, activation='relu', padding=’same’))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(BatchNormalization(epsilon=epsilon))\n",
        "model.add(Dropout(dropout))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=3, activation='relu', padding=’same’))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(BatchNormalization(epsilon=epsilon))\n",
        "model.add(Dropout(dropout))\n",
        "\n",
        "# Aggregation\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "# Fully Connected Layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n"
      ],
      "metadata": {
        "id": "2ND4_WXHKe83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "FhjIbmUpK7U-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer=Adam(0.0001), metrics=['accuracy'])\n",
        "\n",
        "training_steps = 40000//batch_size\n",
        "num_epochs = 10\n",
        "\n",
        "history = model.fit_generator(\n",
        "    training_data,\n",
        "    epochs=num_epochs,\n",
        "    steps_per_epoch = training_steps\n",
        ")\n"
      ],
      "metadata": {
        "id": "k3XxQrcxK9yX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(test_data)\n",
        "y_actual = test_data.classes\n"
      ],
      "metadata": {
        "id": "nYhhg7ztLEXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deepfake Videos"
      ],
      "metadata": {
        "id": "3jH5T7heMNQG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Libraries"
      ],
      "metadata": {
        "id": "EWlxUBkMOxpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries for Machine Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Helper Libraries\n",
        "import imageio\n",
        "import cv2\n",
        "import os\n"
      ],
      "metadata": {
        "id": "eVTCTLGNMRPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loading"
      ],
      "metadata": {
        "id": "c1_OYApUO1MW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_meta_file = '../deepfake-detection-challenge/train_sample_videos/metadata.json'\n",
        "train_sample_metadata = pd.read_json(train_meta_file).T\n",
        "train_sample_metadata.head()"
      ],
      "metadata": {
        "id": "ngGLCtuuMOpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_image(frame):\n",
        "    y = frame.shape[0] \n",
        "    x = frame.shape[1]\n",
        "    min_dimension = min(x, y)\n",
        "    start_x = (x/2) - (min_dimension/2)\n",
        "    start_y = (y/2) - (min_dimension/2)\n",
        "    cropped = frame[start_y : start_y + min_dim, \n",
        "                    start_x : start_x + min_dim]\n",
        "    return cropped\n"
      ],
      "metadata": {
        "id": "AtE5a7qdMy1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_video_into_frames(video_file_path):\n",
        "    new_shape = (224, 224)\n",
        "    capture = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = capture.read()\n",
        "            if not ret: # Have reached the end of frames\n",
        "                break\n",
        "            frame = crop_image(frame)\n",
        "            frame = cv2.resize(frame, new_shape)\n",
        "            frame = frame[:, :, [2, 1, 0]]\n",
        "            frames.append(frame)\n",
        "    finally:\n",
        "        capture.release()\n",
        "    return np.array(frames)\n"
      ],
      "metadata": {
        "id": "13-Q1WdANJht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inception Model for Feature Extraction"
      ],
      "metadata": {
        "id": "WBAmNKgvPMUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inception_model = keras.applications.InceptionV3(\n",
        "        weights=\"imagenet\",\n",
        "        include_top=False,\n",
        "        pooling=\"avg\",\n",
        "        input_shape=(224,224, 3),\n",
        "    )\n",
        "\n",
        "preprocess_input = keras.applications.inception_v3.preprocess_input\n",
        "inputs = keras.Input((224,224, 3))\n",
        "preprocessed = preprocess_input(inputs)\n",
        "outputs = inception_model(preprocessed)\n",
        "feature_extractor = keras.Model(inputs, outputs, name=\"feature_extractor\")\n"
      ],
      "metadata": {
        "id": "bJu92nghNMk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing"
      ],
      "metadata": {
        "id": "mCcD9zQ4PUdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(df, data_dir):\n",
        "    MAX_SEQ_LENGTH = 20\n",
        "    NUM_FEATURES = 2048\n",
        "\n",
        "    num_samples = len(df)\n",
        "    video_paths = list(df.index)\n",
        "    labels = df[\"label\"].values\n",
        "    labels = np.array(labels=='FAKE').astype(np.int)\n",
        "\n",
        "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
        "    frame_features = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
        "\n",
        "    for idx, path in enumerate(video_paths):\n",
        "        # Gather all its frames and add a batch dimension.\n",
        "        frames = parse_video_into_frames(os.path.join(data_dir, path))\n",
        "        frames = frames[None, ...]\n",
        "\n",
        "        # Initialize placeholders to store the masks and features of the current video.\n",
        "        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "        temp_frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
        "\n",
        "        # Extract features from the frames of the current video.\n",
        "        for i, batch in enumerate(frames):\n",
        "            video_length = batch.shape[0]\n",
        "            length = min(MAX_SEQ_LENGTH, video_length)\n",
        "            for j in range(length):\n",
        "                temp_frame_features[i, j, :] = feature_extractor.predict(\n",
        "                    batch[None, j, :]\n",
        "                )\n",
        "            temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
        "\n",
        "        frame_features[idx,] = temp_frame_features.squeeze()\n",
        "        frame_masks[idx,] = temp_frame_mask.squeeze()\n",
        "\n",
        "    return (frame_features, frame_masks), labels\n"
      ],
      "metadata": {
        "id": "oK4mTCrgNd-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training"
      ],
      "metadata": {
        "id": "6JO24UPjPZRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_set, test_set = train_test_split(train_sample_metadata,\n",
        "                   test_size=0.1,\n",
        "                   random_state=42,\n",
        "                   stratify=train_sample_metadata['label'])\n",
        "train_data, train_labels = prepare_data(train_set, \"train\")\n",
        "test_data, test_labels = prepare_data(test_set, \"test\")\n"
      ],
      "metadata": {
        "id": "lFkUkRxfNhbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_SEQ_LENGTH = 20\n",
        "NUM_FEATURES = 2048\n",
        "DROPOUT = 0.2\n",
        "frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
        "mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "\n",
        "x = keras.layers.GRU(32, return_sequences=True)(\n",
        "    frame_features_input, mask=mask_input)\n",
        "x = keras.layers.GRU(16)(x)\n",
        "x = keras.layers.GRU(8)(x)\n",
        "x = keras.layers.Dropout(DROPOUT)(x)\n",
        "x = keras.layers.Dense(8, activation=\"relu\")(x)\n",
        "x = keras.layers.Dense(8, activation=\"relu\")(x)\n",
        "output = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = keras.Model([frame_features_input, mask_input], output)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "2vlwhnUwNpQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "UbDuwntlNxYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "model.fit(\n",
        "        [train_data[0], train_data[1]],\n",
        "        train_labels,\n",
        "        validation_data=([test_data[0], test_data[1]],test_labels),\n",
        "        epochs=EPOCHS,\n",
        "        batch_size=8\n",
        "    )\n"
      ],
      "metadata": {
        "id": "a_2hdZ7bNyIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "cEUMpek4PdKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_labels = []\n",
        "THRESHOLD = 0.5\n",
        "for idx in range(len(test_data[0])):\n",
        "  frame_features = test_data[0][idx]\n",
        "  frame_mask = test_data[1][idx]\n",
        "  output_prob = model.predict([frame_features, frame_mask])[0]\n",
        "  if (output_prob >= THRESHOLD):\n",
        "    predicted_labels.append(1)\n",
        "  else:\n",
        "    predicted_labels.append(0)\n"
      ],
      "metadata": {
        "id": "mqkEjMk2N3pE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}