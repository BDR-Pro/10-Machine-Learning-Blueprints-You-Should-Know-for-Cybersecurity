{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Attacking Image Models"
      ],
      "metadata": {
        "id": "MjRhVfGPyoTe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FGSM Attack"
      ],
      "metadata": {
        "id": "tQFU6F0QysQZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Library Imports"
      ],
      "metadata": {
        "id": "BkVQPSD2yzbv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLCniFBTt6QS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### FGSM Generation Function"
      ],
      "metadata": {
        "id": "40URCi3GyvYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Generate_FGSM_Image(model,\n",
        "                        x,\n",
        "                        epsilon):\n",
        "  \n",
        "  # Check if epsilon is 0\n",
        "  # If so, that means no perturbation is added\n",
        "  # We can avoid gradient calculations\n",
        "  if epsilon == 0:\n",
        "    return x\n",
        "\n",
        "  # Convert x to a float and having gradients enabled\n",
        "  x = x.clone().detach()\n",
        "  x = x.to(torch.float)\n",
        "  x - x.requires_grad_(True)\n",
        "\n",
        "  # Get original label as predicted by model \n",
        "  _, y = torch.max(model(x), 1)\n",
        "\n",
        "  # Compute Loss \n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "  loss = loss_function(model(x), y)\n",
        "\n",
        "  # Backpropagate Loss\n",
        "  loss.backward()\n",
        "\n",
        "  # Calculate perturbation using the FGSM equation\n",
        "  perturbation = epsilon * torch.sign(x.grad)\n",
        "\n",
        "  # Calculate the adversarial image\n",
        "  x_adversarial = x + perturbation \n",
        "\n",
        "  return x_adversarial\n"
      ],
      "metadata": {
        "id": "vB6ArLlPvL2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Basic CNN Classifier"
      ],
      "metadata": {
        "id": "uvJI4s7W1PKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicImageNetCNN(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels=1):\n",
        "        super(BasicImageNetCNN, self).__init__()\n",
        "\n",
        "        # Define the convolutional layers\n",
        "        self.conv1 = nn.Conv2d(in_channels, 64, 8, 1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 6, 2)\n",
        "        self.conv3 = nn.Conv2d(128, 128, 5, 2)\n",
        "\n",
        "        # Define the fully connected layer\n",
        "        self.fc = nn.Linear(128 * 3 * 3, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Pass the imahe through convolutional layers one by one\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "\n",
        "        # Flatten the output of the convolutional layer and pass to fully connected layer\n",
        "        x = x.view(-1, 128 * 3 * 3)\n",
        "        x = self.fc(x)\n",
        "        \n",
        "        return x\n"
      ],
      "metadata": {
        "id": "zn15KinPvOs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataset Setup"
      ],
      "metadata": {
        "id": "07eQFl8g1UQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_cifar10_datasets(datapath):\n",
        "\n",
        "    # Load the transformations\n",
        "    train_transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
        "    test_transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
        "\n",
        "    # Obtain the datasets \n",
        "    # Download them if they are not present\n",
        "    train_dataset = torchvision.datasets.CIFAR10(root=datapath, train=True, \n",
        "                                                 transform=train_transforms, download=True)\n",
        "    test_dataset = torchvision.datasets.CIFAR10(root=datapath, train=False, \n",
        "                                                transform=test_transforms, download=True)\n",
        "\n",
        "    # Create Data Loaders\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, \n",
        "                                               shuffle=True, num_workers=2)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, \n",
        "                                              shuffle=False, num_workers=2)\n",
        "    \n",
        "    return train_loader, test_loader\n"
      ],
      "metadata": {
        "id": "U-7ZznEQvRRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training Base Model"
      ],
      "metadata": {
        "id": "U4XZimlO1Xcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 10\n",
        "\n",
        "train_data, test_data = load_cifar10_datasets(datapath = \"./data\")\n",
        "model = BasicImageNetCNN(in_channels = 3)\n",
        "loss_function = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = \"cuda\"\n",
        "  model = model.cuda()\n",
        "else:\n",
        "  device = \"cpu\"\n",
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  train_loss = 0.0\n",
        "  for x, y in train_data:\n",
        "\n",
        "    # Move image and labels to device if applicable\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    # Zero out the gradients from previous epoch if any\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Calculate predicted value and loss\n",
        "    y_pred = model(x)\n",
        "    loss = loss_function(y_pred, y)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Keep track of the loss\n",
        "    train_loss = train_loss + loss.item()\n",
        "\n",
        "    # Print some information for logging \n",
        "    print(\"EPOCH: {} ---------- Loss: {}\".format(epoch, train_loss))\n"
      ],
      "metadata": {
        "id": "nEVPRzO4vUzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluating FGSM Attack"
      ],
      "metadata": {
        "id": "M72IXktt1bXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "clean_correct = 0\n",
        "fgsm_correct = 0\n",
        "total = 0\n",
        "for x, y in test_data:\n",
        "\n",
        "    # Move image and labels to device if applicable\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    # Calculate the adversarial images\n",
        "    x_fgsm = Generate_FGSM_Image(model, x, epsilon = 0.005)\n",
        "\n",
        "    # Run inference for predicted values on clean and adversarial examples \n",
        "    _, y_pred_clean = torch.max(model(x), 1)\n",
        "    _, y_pred_fgsm = torch.max(model(x_fgsm), 1)\n",
        "\n",
        "    # Calculate accuracy of clean and adversarial predictions\n",
        "    clean_correct = clean_correct + y_pred_clean.eq(y).sum().item()\n",
        "    fgsm_correct = fgsm_correct + y_pred_fgsm.eq(y).sum().item()\n",
        "    total = total + y.size(0)\n",
        "\n",
        "clean_accuracy = clean_correct / total\n",
        "fgsm_accuracy = fgsm_correct / total\n"
      ],
      "metadata": {
        "id": "s7OkighTvYvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PGD Attack"
      ],
      "metadata": {
        "id": "0Y9mg5zS1n_g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Modified FGSM Attack Function"
      ],
      "metadata": {
        "id": "Yn0d6Pht1rp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Generate_FGSM_Image_V2(model,\n",
        "                        x,\n",
        "\t\t\t\t  y, // New Parameter\n",
        "                        epsilon):\n",
        "  \n",
        "  # Check if epsilon is 0\n",
        "  # If so, that means no perturbation is added\n",
        "  # We can avoid gradient calculations\n",
        "  if epsilon == 0:\n",
        "    return x\n",
        "\n",
        "  # Convert x to a float and having gradients enabled\n",
        "  x = x.clone().detach()\n",
        "  x = x.to(torch.float)\n",
        "  x - x.requires_grad_(True)\n",
        "\n",
        "  # Compute Loss \n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "  loss = loss_function(model(x), y)\n",
        "\n",
        "  # Backpropagate Loss\n",
        "  loss.backward()\n",
        "\n",
        "  # Calculate perturbation using the FGSM equation\n",
        "  perturbation = epsilon * torch.sign(x.grad)\n",
        "\n",
        "  # Calculate the adversarial image\n",
        "  x_adversarial = x + perturbation \n",
        "\n",
        "  return x_adversarial\n"
      ],
      "metadata": {
        "id": "W0RP54IavbqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PGDM Attack Function"
      ],
      "metadata": {
        "id": "h5wldTlJ1nbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Generate_PGDM_Image(model,\n",
        "                        x,\n",
        "                        epsilon,\n",
        "                        num_iterations):\n",
        "  \n",
        "  # Obtain actual clean predictions from model\n",
        "  _, y = torch.max(model(x), 1)\n",
        "\n",
        "  # Calclate the initial adversarial value\n",
        "  eta = torch.zeros_like(x)\n",
        "  eta = torch.clamp(eta, -1*eps, 1*eps)\n",
        "  x_adv = x + eta\n",
        "\n",
        "  # For every iteration, do FGSM and clipping \n",
        "  for _ in range(num_iterations):\n",
        "\n",
        "    # Note that the FGSM function signature has changed \n",
        "    # We are passing it the predicted value y as a parameter\n",
        "    # Thus this will not be recomputed\n",
        "    x_adv = Generate_FGSM_Image_V2(model, \n",
        "                                x_adv, \n",
        "                                y,\n",
        "                                epsilon = 0.01)\n",
        "    \n",
        "    eta = x_adv - x\n",
        "    eta = torch.clamp(eta, -1*eps, 1*eps)\n",
        "    x_adv= x + eta\n",
        "\n",
        "  # Return the final image\n",
        "  return x_adv\n"
      ],
      "metadata": {
        "id": "uq7Jv-zaxpjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attacking Text Models"
      ],
      "metadata": {
        "id": "2Ez5224l10k8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Setup"
      ],
      "metadata": {
        "id": "7drkqjs714aP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"FinalBalancedDataset.csv\", skiprows = 1, names= [\"TweetId\",\n",
        "                                                                    \"Toxicity\",\n",
        "                                                                    \"Tweet\"])\n",
        "df.head()"
      ],
      "metadata": {
        "id": "TlI5sm8TxskA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(\"Toxicity\").count()[\"TweetId\"]"
      ],
      "metadata": {
        "id": "4p8_dfiLx1WN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF-IDF Feature Extraction"
      ],
      "metadata": {
        "id": "lMkTItcv177i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "def Extract_TF_IDF(train_data, test_data):\n",
        "\n",
        "    tf_idf = TfidfVectorizer()\n",
        "    X_train_TFIDF = tf_idf.fit_transform(train_data)\n",
        "    X_test_TFIDF = tf_idf.transform(test_data)\n",
        "\n",
        "    return X_train_TFIDF, X_test_TFIDF"
      ],
      "metadata": {
        "id": "RwS1QR6Ax4y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attack Strategies"
      ],
      "metadata": {
        "id": "_DM2yb9X2hPE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Double Last Letter"
      ],
      "metadata": {
        "id": "uBlCnXrn2jQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def double_last_letter(sentences, max_perturbations = 3):\n",
        "\n",
        "    # Output array\n",
        "    modified_sentences = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "\n",
        "        # Split into words\n",
        "        words = sentence.split(' ')\n",
        "\n",
        "        # Randomly choose words to manipulate\n",
        "        rand_indices = np.random.randint(0, len(words), max_perturbations)\n",
        "\n",
        "        for idx in rand_indices:\n",
        "\n",
        "            # Check if the word is blank, if yes, skip\n",
        "            if len(words[idx]) == 0:\n",
        "              continue\n",
        "\n",
        "            # Double the last letter in the chosen word\n",
        "            words[idx]+=words[idx][-1]\n",
        "\n",
        "        # Join back to make sentence\n",
        "        modified_sentences.append(' '.join(word for word in words))\n",
        "\n",
        "    return modified_sentences\n",
        "\n"
      ],
      "metadata": {
        "id": "UupdDegZx8K2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Double Vowel"
      ],
      "metadata": {
        "id": "ax6umbdU2mK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def double_vowel(sentences, max_perturbations = 3):\n",
        "\n",
        "    total_perturbations = 0\n",
        "    # Output array\n",
        "    modified_sentences = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "         \n",
        "        # Split into words\n",
        "        words = sentence.split(' ')\n",
        "\n",
        "        for i in range(len(words)):\n",
        "\n",
        "            # Check if maximum perturbations done\n",
        "            # If so, break the loop and don't do any more!\n",
        "            if total_perturbations>max_perturbations:\n",
        "                break\n",
        "\n",
        "            for vowel in ['a','e','i','o','u']:\n",
        "                if vowel in words[i]:\n",
        "                    words[i] = words[i].replace(vowel,vowel+vowel,1)\n",
        "                    total_perturbations+=1\n",
        "\n",
        "                    # Here replace only for one vowel\n",
        "                    # So once replacement is done, break out \n",
        "                    # This will break only this loop\n",
        "                    break\n",
        "\n",
        "        modified_sentences.append(' '.join(word for word in words))\n",
        "\n",
        "    return modified_sentences"
      ],
      "metadata": {
        "id": "66gjX8HIx_Ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Preparation"
      ],
      "metadata": {
        "id": "03c3Sz7J2vtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[\"Tweet\"].tolist()\n",
        "y = df[\"Toxicity\"].tolist()\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.3, stratify = y)\n",
        "\n",
        "X_train_features, X_test_features = Extract_TF_IDF(X_train, X_test)"
      ],
      "metadata": {
        "id": "r2FRAQP6yIjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation Helper Function"
      ],
      "metadata": {
        "id": "_WBEMU772yvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def evaluate_model(actual, predicted):\n",
        "  confusion = confusion_matrix(actual, predicted)\n",
        "  tn, fp, fn, tp = confusion.ravel()\n",
        "\n",
        "  total = tp + fp + tn + fn\n",
        "\n",
        "  accuracy = 1.0 * (tp + tn) / total\n",
        "  if tp + fp != 0:\n",
        "    precision = tp / (tp + fp)\n",
        "  else:\n",
        "    precision = 0\n",
        "\n",
        "  if tp + fn != 0:\n",
        "    recall = tp / (tp + fn)\n",
        "  else:\n",
        "    recall = 0\n",
        "\n",
        "  if precision == 0 or recall == 0:\n",
        "    f1 = 0\n",
        "  else:\n",
        "    f1 = 2 * precision * recall / (precision + recall)\n",
        "\n",
        "  evaluation = { 'accuracy': accuracy,\n",
        "                 'precision': precision,\n",
        "                 'recall': recall,\n",
        "                 'f1': f1}\n",
        "\n",
        "  return evaluation"
      ],
      "metadata": {
        "id": "Z_Oh9wlCyaKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Base Model Performance"
      ],
      "metadata": {
        "id": "BNAhtelr25NA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier(n_estimators = 100) \n",
        "model.fit(X_train_features, Y_train)\n",
        "Y_predicted = model.predict(X_test_features)\n",
        "evaluation = evaluate_model(Y_test, Y_predicted)\n",
        "\n",
        "print(\"Accuracy: {}\".format(str(evaluation['accuracy'])))\n",
        "print(\"Precision: {}\".format(str(evaluation['precision'])))\n",
        "print(\"Recall: {}\".format(str(evaluation['recall'])))\n",
        "print(\"F-1: {}\".format(str(evaluation['f1'])))"
      ],
      "metadata": {
        "id": "u9EDzgTMyc5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adversarial Attack Performance"
      ],
      "metadata": {
        "id": "jm-6T7LM28Uf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain adversarial samples\n",
        "X_test_adversarial = double_vowel(X_test, max_perturbations=5)\n",
        "\n",
        "# Extract features\n",
        "X_train_features, X_test_features = Extract_TF_IDF(X_train, X_test_adversarial)\n",
        "\n",
        "# Train model\n",
        "model = RandomForestClassifier(n_estimators = 100) \n",
        "model.fit(X_train_features, Y_train)\n",
        "\n",
        "# Predict on adversarial samples\n",
        "Y_predicted = model.predict(X_test_features)\n",
        "\n",
        "# Evaluate\n",
        "evaluation = evaluate_model(Y_test, Y_predicted)\n",
        "print(\"Accuracy: {}\".format(str(evaluation['accuracy'])))\n",
        "print(\"Precision: {}\".format(str(evaluation['precision'])))\n",
        "print(\"Recall: {}\".format(str(evaluation['recall'])))\n",
        "print(\"F-1: {}\".format(str(evaluation['f1'])))"
      ],
      "metadata": {
        "id": "twF9ZKfEyiey"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
