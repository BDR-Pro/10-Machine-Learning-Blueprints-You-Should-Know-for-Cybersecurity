{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5mefAXWFSDF"
      },
      "outputs": [],
      "source": [
        "import bert \n",
        "from bert import run_classifier \n",
        "from bert import optimization \n",
        "from bert import tokenization \n",
        "import tensorflow as tf \n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import tensorflow_hub as hub "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizer"
      ],
      "metadata": {
        "id": "aroiMzPFFjIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_cased_L-12_H-768_A-12/1\" \n",
        "\n",
        " \n",
        "\n",
        "def create_tokenizer_from_hub_module(): \n",
        "\n",
        "  with tf.Graph().as_default(): \n",
        "\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB) \n",
        "\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True) \n",
        "\n",
        "    with tf.Session() as sess: \n",
        "\n",
        "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"], \n",
        "\n",
        "                                            tokenization_info[\"do_lower_case\"]]) \n",
        "\n",
        "       \n",
        "\n",
        "  return bert.tokenization.FullTokenizer( \n",
        "\n",
        "      vocab_file=vocab_file, do_lower_case=do_lower_case) \n",
        "\n",
        " \n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module() "
      ],
      "metadata": {
        "id": "KRXU8E9xFe6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the Classification Model"
      ],
      "metadata": {
        "id": "Pl1wThPCGJav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels, \n",
        "\n",
        "                 num_labels): \n",
        "\n",
        "  \"\"\"Creates a classification model.\"\"\" \n",
        "\n",
        " \n",
        "\n",
        "  bert_module = hub.Module( \n",
        "\n",
        "      BERT_MODEL_HUB, \n",
        "\n",
        "      trainable=True) \n",
        "\n",
        "  bert_inputs = dict( \n",
        "\n",
        "      input_ids=input_ids, \n",
        "\n",
        "      input_mask=input_mask, \n",
        "\n",
        "      segment_ids=segment_ids) \n",
        "\n",
        "  bert_outputs = bert_module( \n",
        "\n",
        "      inputs=bert_inputs, \n",
        "\n",
        "      signature=\"tokens\", \n",
        "\n",
        "      as_dict=True) \n",
        "\n",
        "  output_layer = bert_outputs[\"pooled_output\"] \n",
        "\n",
        "  hidden_size = output_layer.shape[-1].value \n",
        "\n",
        "  output_weights = tf.get_variable( \n",
        "\n",
        "      \"output_weights\", [num_labels, hidden_size],        initializer=tf.truncated_normal_initializer(stddev=0.02)) \n",
        "\n",
        " \n",
        "\n",
        "  output_bias = tf.get_variable( \n",
        "\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer()) \n",
        "\n",
        " \n",
        "\n",
        "  with tf.variable_scope(\"loss\"): \n",
        "\n",
        " \n",
        "\n",
        "    # Dropout helps prevent overfitting \n",
        "\n",
        "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9) \n",
        "\n",
        " \n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True) \n",
        "\n",
        "    logits = tf.nn.bias_add(logits, output_bias) \n",
        "\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1) \n",
        "\n",
        " \n",
        "\n",
        "    # Convert labels into one-hot encoding \n",
        "\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32) \n",
        "\n",
        " \n",
        "\n",
        "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32)) \n",
        "\n",
        "    # If we're predicting, we want predicted labels and the probabilties. \n",
        "\n",
        "    if is_predicting: \n",
        "\n",
        "      return (predicted_labels, log_probs) \n",
        "\n",
        " \n",
        "\n",
        "    # If we're train/eval, compute loss between predicted and actual label \n",
        "\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1) \n",
        "\n",
        "    loss = tf.reduce_mean(per_example_loss) \n",
        "\n",
        "    return (loss, predicted_labels, log_probs) "
      ],
      "metadata": {
        "id": "t7guljPIFosd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the Model Function"
      ],
      "metadata": {
        "id": "S72DYlJ8GNeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_fn_builder(num_labels, learning_rate, num_train_steps,num_warmup_steps): \n",
        "\n",
        "  def model_fn(features, labels, mode, params): \n",
        "\n",
        " \n",
        "\n",
        "    input_ids = features[\"input_ids\"] \n",
        "\n",
        "    input_mask = features[\"input_mask\"] \n",
        "\n",
        "    segment_ids = features[\"segment_ids\"] \n",
        "\n",
        "    label_ids = features[\"label_ids\"] \n",
        "\n",
        " \n",
        "\n",
        "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT) \n",
        "\n",
        "     \n",
        "\n",
        "    # TRAIN and EVAL \n",
        "\n",
        "    if not is_predicting: \n",
        "\n",
        " \n",
        "\n",
        "      (loss, predicted_labels, log_probs) = create_model( \n",
        "\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels) \n",
        "\n",
        " \n",
        "\n",
        "      train_op = bert.optimization.create_optimizer( \n",
        "\n",
        "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False) \n",
        "\n",
        " \n",
        "\n",
        "      # Calculate evaluation metrics.  \n",
        "\n",
        "      def metric_fn(label_ids, predicted_labels): \n",
        "\n",
        "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels) \n",
        "\n",
        "        f1_score = tf.contrib.metrics.f1_score( \n",
        "\n",
        "            label_ids, \n",
        "\n",
        "            predicted_labels) \n",
        "\n",
        "        auc = tf.metrics.auc( \n",
        "\n",
        "            label_ids, \n",
        "\n",
        "            predicted_labels) \n",
        "\n",
        "        recall = tf.metrics.recall( \n",
        "\n",
        "            label_ids, \n",
        "\n",
        "            predicted_labels) \n",
        "\n",
        "        precision = tf.metrics.precision( \n",
        "\n",
        "            label_ids, \n",
        "\n",
        "            predicted_labels)  \n",
        "\n",
        "        true_pos = tf.metrics.true_positives( \n",
        "\n",
        "            label_ids, \n",
        "\n",
        "            predicted_labels) \n",
        "\n",
        "        true_neg = tf.metrics.true_negatives( \n",
        "\n",
        "            label_ids, \n",
        "\n",
        "            predicted_labels)    \n",
        "\n",
        "        false_pos = tf.metrics.false_positives( \n",
        "\n",
        "            label_ids, \n",
        "\n",
        "            predicted_labels)   \n",
        "\n",
        "        false_neg = tf.metrics.false_negatives( \n",
        "\n",
        "            label_ids, \n",
        "\n",
        "            predicted_labels) \n",
        "\n",
        "        return { \n",
        "\n",
        "            \"eval_accuracy\": accuracy, \n",
        "\n",
        "            \"f1_score\": f1_score, \n",
        "\n",
        "            \"auc\": auc, \n",
        "\n",
        "            \"precision\": precision, \n",
        "\n",
        "            \"recall\": recall, \n",
        "\n",
        "            \"true_positives\": true_pos, \n",
        "\n",
        "            \"true_negatives\": true_neg, \n",
        "\n",
        "            \"false_positives\": false_pos, \n",
        "\n",
        "            \"false_negatives\": false_neg \n",
        "\n",
        "        } \n",
        "\n",
        " \n",
        "\n",
        "      eval_metrics = metric_fn(label_ids, predicted_labels) \n",
        "\n",
        " \n",
        "\n",
        "      if mode == tf.estimator.ModeKeys.TRAIN: \n",
        "\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, \n",
        "\n",
        "          loss=loss, \n",
        "\n",
        "          train_op=train_op) \n",
        "\n",
        "      else: \n",
        "\n",
        "          return tf.estimator.EstimatorSpec(mode=mode, \n",
        "\n",
        "            loss=loss, \n",
        "\n",
        "            eval_metric_ops=eval_metrics) \n",
        "\n",
        "    else: \n",
        "\n",
        "      (predicted_labels, log_probs) = create_model( \n",
        "\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels) \n",
        "\n",
        " \n",
        "\n",
        "      predictions = { \n",
        "\n",
        "          'probabilities': log_probs, \n",
        "\n",
        "          'labels': predicted_labels \n",
        "\n",
        "      } \n",
        "\n",
        "      return tf.estimator.EstimatorSpec(mode, predictions=predictions) \n",
        "\n",
        " \n",
        "\n",
        "  # Return the actual model function in the closure \n",
        "\n",
        "  return model_fn "
      ],
      "metadata": {
        "id": "Qv4hOcWDFsRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset and Setup"
      ],
      "metadata": {
        "id": "3wnqZNKCGu0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32 \n",
        "\n",
        "LEARNING_RATE = 2e-5 \n",
        "\n",
        "NUM_TRAIN_EPOCHS = 3.0 \n",
        "\n",
        "WARMUP_PROPORTION = 0.1 \n",
        "\n",
        " \n",
        "\n",
        "SAVE_CHECKPOINTS_STEPS = 500 \n",
        "\n",
        "SAVE_SUMMARY_STEPS = 100 \n",
        "\n",
        " \n",
        "\n",
        "POSRATIO=0.001 # 0.1% \n",
        "\n",
        "NPOS=10000*POSRATIO "
      ],
      "metadata": {
        "id": "bNvFTEBPFxaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_a=pd.read_csv('dataset.csv') \n",
        "\n",
        "df_a_1=df_a[df_a['VERDICT']==1] \n",
        "\n",
        "df_a_0=df_a[df_a['VERDICT']==0] \n",
        "\n",
        "df_a_sampled=pd.concat([df_a_1[:nPos],df_a_0[:NPOS]])  "
      ],
      "metadata": {
        "id": "-Wbr-kmhF0Dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "df_train_n,df_test_n=train_test_split(df_a_sampled,stratify=df_a_sampled['VERDICT']) "
      ],
      "metadata": {
        "id": "ek8xuT3tF20W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_COLUMN='API_CALL_SEQ' \n",
        "\n",
        "LABEL_COLUMN='VERDICT' \n",
        "\n",
        "train_InputExamples_a = df_train_n.apply(lambda x: bert.run_classifier.InputExample(guid=None,  \n",
        "\n",
        "  text_a = x[DATA_COLUMN],  \n",
        "\n",
        "  \t\t\t  text_b = None,  \n",
        "\n",
        "  label = x[LABEL_COLUMN]),  \n",
        "\n",
        "  axis = 1) \n",
        "\n",
        " \n",
        "\n",
        "test_InputExamples_a = df_test_n.apply(lambda x: bert.run_classifier.InputExample(guid=None,  \n",
        "\n",
        "  text_a = x[DATA_COLUMN],  \n",
        "\n",
        "  \t\t\t  text_b = None,  \n",
        "\n",
        "  label = x[LABEL_COLUMN]),  \n",
        "\n",
        "  axis = 1) "
      ],
      "metadata": {
        "id": "kH5uhpv3F5LS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_list=[0,1] \n",
        "\n",
        "MAX_SEQ_LENGTH = 128 \n",
        "\n",
        " \n",
        "\n",
        "train_features_a = bert.run_classifier.convert_examples_to_features( \n",
        "\n",
        "                train_InputExamples_a,  \n",
        "\n",
        "                label_list,  \n",
        "\n",
        "                MAX_SEQ_LENGTH,  \n",
        "\n",
        "                tokenizer) \n",
        "\n",
        "test_features_a = bert.run_classifier.convert_examples_to_features( \n",
        "\n",
        "                test_InputExamples_a,  \n",
        "\n",
        "                label_list,  \n",
        "\n",
        "                MAX_SEQ_LENGTH,  \n",
        "\n",
        "                tokenizer) "
      ],
      "metadata": {
        "id": "P5LFY1GcF79t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "ihefENhuG0Rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_DIR='saved_models/rate_'+str(posRatio*100) \n",
        "\n",
        "num_train_steps = int(len(train_features_a) / BATCH_SIZE * NUM_TRAIN_EPOCHS) \n",
        "\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION) \n",
        "\n",
        " \n",
        "\n",
        "run_config = tf.estimator.RunConfig( \n",
        "\n",
        "    model_dir=OUTPUT_DIR, \n",
        "\n",
        "    save_summary_steps=SAVE_SUMMARY_STEPS, \n",
        "\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS) \n",
        "\n",
        " \n",
        "\n",
        "model_fn = model_fn_builder( \n",
        "\n",
        "  num_labels=len(label_list), \n",
        "\n",
        "  learning_rate=LEARNING_RATE, \n",
        "\n",
        "  num_train_steps=num_train_steps, \n",
        "\n",
        "  num_warmup_steps=num_warmup_steps) \n",
        "\n",
        " \n",
        "\n",
        "estimator_android = tf.estimator.Estimator( \n",
        "\n",
        "  model_fn=model_fn, \n",
        "\n",
        "  config=run_config, \n",
        "\n",
        "  params={\"batch_size\": BATCH_SIZE}) \n",
        "\n",
        " \n",
        "\n",
        "train_input_fn_a = bert.run_classifier.input_fn_builder( \n",
        "\n",
        "    features=train_features_a, \n",
        "\n",
        "    seq_length=MAX_SEQ_LENGTH, \n",
        "\n",
        "    is_training=True, \n",
        "\n",
        "    drop_remainder=False) \n",
        "\n",
        " \n",
        "\n",
        "import time \n",
        "\n",
        "print(f'Beginning Training!') \n",
        "\n",
        "current_time = time.time() \n",
        "\n",
        "estimator_android.train(input_fn=train_input_fn_a, max_steps=num_train_steps) \n",
        "\n",
        "print(\"Training took time \", time.time() - current_time) "
      ],
      "metadata": {
        "id": "h95jJLnOF-cF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "L3HOCYFYG22_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_input_fn_a = bert.run_classifier.input_fn_builder( \n",
        "\n",
        "    features=test_features_a, \n",
        "\n",
        "    seq_length=MAX_SEQ_LENGTH, \n",
        "\n",
        "    is_training=False, \n",
        "\n",
        "    drop_remainder=False) \n",
        "\n",
        " \n",
        "\n",
        "metrics = estimator_android.evaluate(input_fn=test_input_fn_a, steps=None) "
      ],
      "metadata": {
        "id": "HAP4XhuzGCbQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
